---
title: FieldTrip tutorial at the Donders Cognition Brain and Technology school
tags: [bcbt2022]
---

# FieldTrip tutorial at the Donders Cognition Brain and Technology school

- Who: Robert Oostenveld
- When: 5 to 16 September 2022
- Where: Nijmegen
- See <https://bcbt.specs-lab.com/bcbt22/about/> for more details

In this tutorial, which runs over two afternoons (Tue 7 and Wed 8 September) in the first week of the DCBT school, we will give an introduction to EEG and MEG data, its neuronal generators and how it is recorded. Subsequently, we will explain how to use the FieldTrip toolbox to analyze the data with different levels of sophistication.

On Tuesday afternoon the focus will be on interpreting the EEG and MEG signals, we will do a EEG data acquisition demonstration (you can try it yourself), will look at the typical artifacts to consider in the data and we will look at preprocessing. On Wednesday afternoon we will look at spectral analysis, source reconstruction, measures of connectivity and network analysis. Both days will comprise a combination of short lectures and hands-on MATLAB exercises on a tutorial dataset.

In the second week of the DCBT school, participants carry out a short project. We will have time to provide feedback on the projects and to address follow up questions resulting from the projects.

_We will keep this page up to date and post new information here when available._

## The data used in this tutorial

We will be using the [eeg-language](/tag/eeg-language) dataset that has been converted to BIDS. The data is available from our [download server](https://download.fieldtriptoolbox.org/workshop/cuttingeeg2021/) and is alternatively available from <https://zenodo.org/communities/cuttingeeg>.

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5531370.svg)](https://doi.org/10.5281/zenodo.5531370)

The conversion of the 5 pilot subjects' EEG data to BIDS is fully documented on [this page](/workshop/cuttingeeg2021/bids_language). You don't have to run that code, but you can use it as inspiration for organizing your own data in the [BIDS format](/example/other/bids), or use it to convert the full dataset that is available from the [archive of the MPI for Psycholinguistics](https://hdl.handle.net/1839/00-0000-0000-001B-860D-8).

The "minimal" dataset (~260MB) contains one subject and is enough to run the tutorial. The "pilot" dataset (~1.7GB) contains all 5 subjects used for the pilot analysis in the original paper; you can use that if you want to explore other subjects with this tutorial.

### Experimental paradigm

EEG data was recorded while participants attended the stimuli corresponding to concepts from three semantic categories: two categories that were relevant for the main analysis in the original study (animals, tools) and a response task category that varied across subjects (either clothing or vegetables). There were four exemplars per category. All exemplars were presented in three modalities: auditory (spoken Dutch words recorded digitally at 16 bits with a sampling rate of 44.100 Hz), visual (black line drawings on white background) [38] and orthographical (written Dutch words, black letters on white background). Pictures were matched for familiarity and complexity. Each of the relevant items was repeated eighty times in each modality. Task items were repeated sixteen times and shown approximately once per ten relevant items.

The recorded brain activity includes visual, orthographic, and auditory activity (for the modalities), and semantic activity (for the categories). Furthermore, the task condition includes motor preparation and execution.

## Possible ideas for short projects

- Classification of trials between stimulus type (visual and auditory)
- Classification of trials between modalities (picture, text, spoken)
- Classification of trials between categories (animals, tools)
- Identification of temporal activation sequence (from sensory to conceptual)
- Identification of temporal activation sequence in the task data (from sensory to conceptual to motor)
- Identification of shared semantic representation between modalities
- Localization of sources corresponding to sensory, conceptual and/or motor activity
- Identification of cortical network (from sensory to conceptual)
- Identification of cortical network in the task data (from sensory to conceptual to motor)

## Getting started with the hands-on session

{% include markup/red %}
Please download and unzip a recent version of FieldTrip from <https://github.com/fieldtrip/fieldtrip/releases>. We will be using some cutting edge features in FieldTrip, so you should download and install release [20220819](http://github.com/fieldtrip/fieldtrip/releases/tag/20220819) or later.
{% include markup/end %}

To get going, you need to start MATLAB. Then, you need to issue the following commands:

    restoredefaultpath
    cd <your_fieldtrip_location>
    addpath(pwd)
    ft_defaults

The `<your_fieldtrip_location>` is the directory in which all the code is after you have unzipped the downloaded folder.

{% include markup/red %}
Please do NOT use the graphical path management tool from MATLAB. In this hands-on session we'll manage the path from the command line, but in general you are much better off using the `startup.m` file than the path GUI.

Please do NOT add FieldTrip with all subdirectories, subdirectories will be added automatically when needed, and only when needed. See also this [frequently asked question](/faq/matlab/installation).
{% include markup/end %}

The `restoredefaultpath` command clears your path, keeping only the official MATLAB toolboxes. The `addpath(pwd)` statement adds the present working directory, i.e. the directory containing the FieldTrip main functions. The `ft_defaults` command ensures that all required subdirectories are added to the path.

If you get the error "can't find the command ft_defaults" you should check that you are in the correct directory.

After installing FieldTrip to your path, you need to change into the hands-on specific directory, containing the data that is necessary to run the hands-on session.
